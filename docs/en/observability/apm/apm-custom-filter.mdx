---
id: enObservabilityApmCustomFilter
slug: /en/observability/apm-custom-filter
title: Custom filters
description: Description to be written
tags: []
---

import CustomFilters from './apm-data-security/custom-filters.mdx'
import IngestPipelineNaming from './ingest-pipelines/ingest-pipeline-naming.mdx'

<div id="apm-custom-filter"></div>

<CustomFilters />

<div id="apm-filters-ingest-pipeline"></div>

## Create an ingest pipeline filter

Ingest node pipelines specify a series of processors that transform data in a specific way.
Transformation happens prior to indexing--inflicting no performance overhead on the monitored application.
Pipelines are a flexible and easy way to filter or obfuscate Elastic APM data.

<div id="apm-filters-ingest-pipeline-tutorial"></div>

### Tutorial: redact sensitive information

Say you decide to <DocLink id="enObservabilityApmFiltering" section="http-bodies">capture HTTP request bodies</DocLink>
but quickly notice that sensitive information is being collected in the
`http.request.body.original` field:

```json
{
  "email": "test@abc.com",
  "password": "hunter2"
}
```

**Create a pipeline**

To obfuscate the passwords stored in the request body,
you can use a series of [ingest processors](((ref))/processors.html).
To start, create a pipeline with a simple description and an empty array of processors:

```json
{
  "pipeline": {
    "description": "redact http.request.body.original.password",
    "processors": []  [^1]
  }
}
```
[^1]: The processors defined below will go in this array

**Add a JSON processor**

Add your first processor to the processors array.
Because the agent captures the request body as a string, use the
[JSON processor](((ref))/json-processor.html) to convert the original field value into a structured JSON object.
Save this JSON object in a new field:

```json
{
  "json": {
    "field": "http.request.body.original",
    "target_field": "http.request.body.original_json",
    "ignore_failure": true
  }
}
```

**Add a set processor**

If `body.original_json` is not `null`, i.e., it exists, we'll redact the `password` with the [set processor](((ref))/set-processor.html),
by setting the value of `body.original_json.password` to `"redacted"`:

```json
{
  "set": {
    "field": "http.request.body.original_json.password",
    "value": "redacted",
    "if": "ctx?.http?.request?.body?.original_json != null"
  }
}
```

**Add a convert processor**

Use the [convert processor](((ref))/convert-processor.html) to convert the JSON value of `body.original_json` to a string and set it as the `body.original` value:

```json
{
  "convert": {
    "field": "http.request.body.original_json",
    "target_field": "http.request.body.original",
    "type": "string",
    "if": "ctx?.http?.request?.body?.original_json != null",
    "ignore_failure": true
  }
}
```

**Add a remove processor**

Finally, use the [remove processor](((ref))/remove-processor.html) to remove the `body.original_json` field:

```json
{
  "remove": {
    "field": "http.request.body.original",
    "if": "ctx?.http?.request?.body?.original_json != null",
    "ignore_failure": true
  }
}
```

**Register the pipeline**

Now we'll put it all together.
Use the [create or update pipeline API](((ref))/put-pipeline-api.html) to register the new pipeline in ((es)).
Name the pipeline `apm_redacted_body_password`:

```console
PUT _ingest/pipeline/apm_redacted_body_password
{
  "description": "redact http.request.body.original.password",
  "processors": [
    {
      "json": {
        "field": "http.request.body.original",
        "target_field": "http.request.body.original_json",
        "ignore_failure": true
      }
    },
    {
      "set": {
        "field": "http.request.body.original_json.password",
        "value": "redacted",
        "if": "ctx?.http?.request?.body?.original_json != null"
      }
    },
    {
      "convert": {
        "field": "http.request.body.original_json",
        "target_field": "http.request.body.original",
        "type": "string",
        "if": "ctx?.http?.request?.body?.original_json != null",
        "ignore_failure": true
      }
    },
    {
      "remove": {
        "field": "http.request.body.original_json",
        "if": "ctx?.http?.request?.body?.original_json != null",
        "ignore_failure": true
      }
    }
  ]
}
```

**Test the pipeline**

Prior to enabling this new pipeline, you can test it with the [simulate pipeline API](((ref))/simulate-pipeline-api.html).
This API allows you to run multiple documents through a pipeline to ensure it is working correctly.

The request below simulates running three different documents through the pipeline:

```console
POST _ingest/pipeline/apm_redacted_body_password/_simulate
{
  "docs": [
    {
      "_source": {  [^1]
        "http": {
          "request": {
            "body": {
              "original": """{"email": "test@abc.com", "password": "hunter2"}"""
            }
          }
        }
      }
    },
    {
      "_source": {  [^2]
        "some-other-field": true
      }
    },
    {
      "_source": {  [^3]
        "http": {
          "request": {
            "body": {
              "original": """["invalid json" """
            }
          }
        }
      }
    }
  ]
}
```
[^1]: This document features the same sensitive data from the original example above
[^2]: This document only contains an unrelated field
[^3]: This document contains invalid JSON

The API response should be similar to this:

```json
{
  "docs" : [
    {
      "doc" : {
        "_source" : {
          "http" : {
            "request" : {
              "body" : {
                "original" : {
                  "password" : "redacted",
                  "email" : "test@abc.com"
                }
              }
            }
          }
        }
      }
    },
    {
      "doc" : {
        "_source" : {
          "nobody" : true
        }
      }
    },
    {
      "doc" : {
        "_source" : {
          "http" : {
            "request" : {
              "body" : {
                "original" : """["invalid json" """
              }
            }
          }
        }
      }
    }
  ]
}
```

As expected, only the first simulated document has a redacted password field.
All other documents are unaffected.

**Create an `@custom` pipeline**

The final step in this process is to call the newly created `apm_redacted_body_password` pipeline
from the `@custom` pipeline of the data stream you wish to edit.

<IngestPipelineNaming />

Use the [create or update pipeline API](((ref))/put-pipeline-api.html) to register the new pipeline in ((es)).
Name the pipeline `traces-apm@custom`:

```console
PUT _ingest/pipeline/traces-apm@custom
{
  "processors": [
    {
      "pipeline": {
        "name": "apm_redacted_body_password"  [^1]
      }
    }
  ]
}
```
[^1]: The name of the pipeline we previously created

<DocCallOut title="Tip">
If you prefer using a GUI, you can instead open ((kib)) and navigate to
**Stack Management** -> **Ingest Pipelines** -> **Create pipeline**.
Use the same naming convention explained previously to ensure your new pipeline matches the correct APM data stream.
</DocCallOut>

That's it! Passwords will now be redacted from your APM HTTP body data.

To learn more about ingest pipelines, see <DocLink id="enObservabilityApmCustomIndexTemplate" section="view-the-((es))-index-template">View the ((es)) index template</DocLink>.

<div id="apm-filters-in-agent"></div>

## APM agent filters

Some APM agents offer a way to manipulate or drop APM events _before_ they are sent to the APM Server.
Please see the relevant agent's documentation for more information and examples:

{/* * Go: ((apm-go-ref-v))/[] */}
{/* * Java: ((apm-java-ref-v))/[] */}
* .NET: [Filter API](((apm-dotnet-ref-v))/public-api.html#filter-api).
* Node.js: [`addFilter()`](((apm-node-ref-v))/agent-api.html#apm-add-filter).
{/* * PHP: ((apm-php-ref-v))[] */}
* Python: [custom processors](((apm-py-ref-v))/sanitizing-data.html).
* Ruby: [`add_filter()`](((apm-ruby-ref-v))/api.html#api-agent-add-filter).

{/* **************************************************************** */}

