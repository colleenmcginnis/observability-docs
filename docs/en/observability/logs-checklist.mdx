---
slug: /en/observability/logs-checklist
title: Log monitoring
description: Description to be written
tags: []
---

<div id="logs-checklist"></div>

Logs are an important tool for ensuring the performance and reliability of your applications and infrastructure. They provide important information for debugging, analyzing performance, and managing compliance.

On this page, you'll find resources for sending log data to ((es)), configuring your logs, and analyzing your logs.

<div id="logs-getting-started-checklist"></div>

## Get started with logs

For a high-level overview on ingesting, viewing, and analyzing logs with Elastic, refer to <DocLink slug="/en/observability/logs-metrics-get-started">Get started with logs and metrics</DocLink>.

To get started ingesting, parsing, and filtering your own data, refer to these pages:

* **<DocLink slug="/en/observability/logs-stream">Stream any log file</DocLink>**: send log files from your system to ((es)) using a standalone ((agent)) and configure the ((agent)) and your data streams using the `elastic-agent.yml` file.
* **<DocLink slug="/en/observability/logs-parse">Parse and organize logs</DocLink>**: break your log messages into meaningful fields that you can use to filter and analyze your data.
* **<DocLink slug="/en/observability/logs-filter-and-aggregate">Filter and aggregate logs</DocLink>**: find specific information in your log data to gain insight and monitor your systems.

The following sections provide resources to important concepts or advanced use cases for working with your logs.

<div id="logs-send-data-checklist"></div>

## Send log data to ((es))

You can send log data to ((es)) in different ways depending on your needs:

* **((agent))**: a single agent for logs, metrics, security data, and threat prevention. It can be deployed either standalone or managed by ((fleet)):
    * **Standalone**: Manually configure, deploy and update an ((agent)) on each host.
    * **Fleet**: Centrally manage and update ((agent)) policies and lifecycles in ((kib)).
* **((filebeat))**: a lightweight, logs-specific shipper for forwarding and centralizing log data.

Refer to the [((agent)) and ((beats)) capabilities comparison](((fleet-guide))/beats-agent-comparison.html) for more information on which option best fits your situation.

<div id="agent-ref-guide"></div>

### Install ((agent))
The following pages detail installing and managing the ((agent)) in different modes.

* **Standalone ((agent))**

    Install an ((agent)) and manually configure it locally on the system where it's installed.
    You are responsible for managing and upgrading the agents.

    Refer to <DocLink slug="/en/observability/logs-stream">Stream any log file</DocLink> to learn how to send a log file to ((es)) using a standalone ((agent)) and configure the ((agent)) and your data streams using the `elastic-agent.yml` file.

* **((fleet))-managed ((agent))**

    Install an ((agent)) and use ((fleet)) in ((kib)) to define, configure, and manage your agents in a central location.

    Refer to [install ((fleet))-managed ((agent))](((fleet-guide))/install-fleet-managed-elastic-agent.html).

* **((agent)) in a containerized environment**

    Run an ((agent)) inside of a containerâ€”either with ((fleet-server)) or standalone.

    Refer to [install ((agent)) in a containerized environment](((fleet-guide))/install-elastic-agents-in-containers.html).

<div id="beats-ref-guide"></div>

### Install ((filebeat))
((filebeat)) is a lightweight shipper for forwarding and centralizing log data.
Installed as a service on your servers, ((filebeat)) monitors the log files or locations that you specify, collects log events, and forwards them
either to [((es))](((ref))) or
[Logstash](((logstash-ref))) for indexing.

- [((filebeat)) overview](((filebeat-ref))/filebeat-overview.html): general information on ((filebeat)) and how it works.
- [((filebeat)) quick start](((filebeat-ref))/filebeat-installation-configuration.html): basic installation instructions to get you started.
- [Set up and run ((filebeat))](((filebeat-ref))/setting-up-and-running.html): information on how to install, set up, and run ((filebeat)).

<div id="logs-configure-data-checklist"></div>

## Parse and organize your logs

To get started parsing and organizing your logs, refer to <DocLink slug="/en/observability/logs-parse">Parse and organize logs</DocLink> for information on breaking unstructured log data into meaningful fields you can use to filter and aggregate your data.

The following resources provide information on important concepts related to parsing and organizing your logs:

- [Data streams](((ref))/data-streams.html): Efficiently store append-only time series data in multiple backing indices partitioned by time and size.
- [Data views](((kibana-ref))/data-views.html): Query log entries from the data streams of specific datasets or namespaces.
- [Index lifecycle management](((ref))/example-using-index-lifecycle-policy.html): Configure the built-in logs policy based on your application's performance, resilience, and retention requirements.
- [Ingest pipeline](((ref))/ingest.html): Parse and transform log entries into a suitable format before indexing.
- [Mapping](((ref))/mapping.html): define how data is stored and indexed.

<div id="logs-monitor-checklist"></div>

## View and monitor logs

With the ((logs-app)) in ((kib)) you can search, filter, and tail all your logs ingested into ((es)) in one place.

The following resources provide information on viewing and monitoring your logs:

- <DocLink slug="/en/observability/tail-logs">Tail log files</DocLink>: monitor all of the log events flowing in from your servers, virtual machines, and containers in a centralized view.
- <DocLink slug="/en/observability/inspect-log-anomalies">Inspect log anomalies</DocLink>: use ((ml)) to detect log anomalies automatically.
- <DocLink slug="/en/observability/categorize-logs">Categorize log entries</DocLink>: use ((ml)) to categorize log messages to quickly identify patterns in your log events.
- <DocLink slug="/en/observability/configure-data-sources">Configure data sources</DocLink>: Specify the source configuration for logs in the Logs app settings in the Kibana configuration file.

<div id="logs-checklist-k8s"></div>

## Monitor Kubernetes logs

You can use the ((agent)) with the Kubernetes integration to collect and parse Kubernetes logs.
Refer to <DocLink slug="/en/observability/monitor-kubernetes">Monitor Kubernetes: Observe the health and performance of your Kubernetes deployments</DocLink>.

<div id="logs-app-checklist"></div>

## View and monitor application logs

Application logs provide valuable insight into events that have occurred within your services and applications.

Refer to <DocLink slug="/en/observability/application-logs">Stream application logs</DocLink>.

<div id="logs-alerts-checklist"></div>

## Create a log threshold alert

You can create a rule to send an alert when the log aggregation exceeds a threshold.
See <DocLink slug="/en/observability/logs-threshold-alert">Create a log threshold rule</DocLink>.
